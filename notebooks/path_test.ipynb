{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very basic jupyter tutorial for the Hereditary Depth First Search (HDFS) from the pathfinder module.\n",
    "\n",
    "The aim of this exercise is to identify the optimum subset of elements where elements could refer to a sets of features for ML training, Linear Regression or experimental observables. Given access to a pair wise relation matrix - e.g. Pearson Correlation, Fisher Information, Joint Mutual Information, ... - one can construct a Binary Acceptance Matrix (BAM) by defining a threshold (T) below which combination is allowed. The HDFS algorithm will efficiently identify all subsets of elements whose pairwise relations fall below T for all elements in the subset. Thus the HDFS algorithm provides a list of subsets containing minimally 'related' elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import numpy as np\n",
    "import pathfinder as pf\n",
    "from pathfinder import plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for the pseudo data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed) \n",
    "print(f\"seed = {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create the \"Binary Acceptance Matrix\" (BAM). \\\n",
    "\\\n",
    "The BAM ($\\rho$) is a symmetric Boolean matrix that provides the pair-wise combination condition i.e element $i$ can be combined with elemet $j$ if $\\rho_{ij}$ = True  \\\n",
    "\\\n",
    "For this example we will create a 'psudo' BAM by randomly generating matrix elements with Boolean values distributed as follows:\n",
    "\n",
    "$ P(\\rho_{ij}=True) = p$ \\\n",
    "\\\n",
    " $P(\\rho_{ij}=False) = 1-p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25                                                                          # Matrix size\n",
    "p = 0.5                                                                         # Distribution of True values \n",
    "pseudo = np.triu(np.random.choice([True, False], size=(N,N), p=[p, 1-p]), 1)    # Construct BAM values \n",
    "pseudo += pseudo.T                                                              # Construct symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exsersise is to identify the optimum subset of elements.\n",
    "The HDFS algorithm identifies **all** allowed subsets elements using the Binary Acceptance Matrix.\n",
    "To help choose the optimum set one can provide a list of weights which will give preference to the highest total path weight sum. \n",
    "If run without weight the \"**find_paths**\" method will return the longest paths as if uniformly weighted to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo weights\n",
    "weights = np.random.rand(N)\n",
    "labels = [f'F{i}' for i in range(N)]\n",
    "# Provide pseudo BAM and Weights to BinaryAcceptance class\n",
    "bam = pf.BinaryAcceptance(pseudo, weights=weights, labels=labels)\n",
    "# Plot the BAM\n",
    "plot_results.plot(bam, size=10)                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the **BinaryAcceptance** Object to **HDFS** and run **find_paths** to get the top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = pf.find_best_combinations(matrix=pseudo,\n",
    "                                 weights=weights,\n",
    "                                 top=5, \n",
    "                                 allow_subset=False, \n",
    "                                 verbose=True,\n",
    "                                 labels=labels,\n",
    "                                 algorithm='hdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the **BinaryAcceptance** Object to **WHDFS** and run **find_paths** to get the top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whdfs = pf.find_best_combinations(matrix=pseudo,\n",
    "                                  weights=weights,\n",
    "                                  top=5, \n",
    "                                  allow_subset=False, \n",
    "                                  verbose=True,\n",
    "                                  labels=labels,\n",
    "                                  algorithm='whdfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected result\n",
    "1: Path = [1, 7, 15, 16, 22, 23],  Weight = 4.499650470394825,  \n",
    "\n",
    "2: Path = [1, 9, 16, 22, 23],  Weight = 3.992302162921413,  \n",
    "\n",
    "3: Path = [2, 13, 14, 15, 17],  Weight = 3.8649178973867615,  \n",
    "\n",
    "4: Path = [2, 7, 14, 15, 17],  Weight = 3.707504655554509,  \n",
    "\n",
    "5: Path = [2, 8, 13, 14, 17],  Weight = 3.5387637906697584  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHDFS Vs HDFS results comparison:\")\n",
    "print(f\"Weight comparison: {all([np.isclose(w.weight, h.weight) for w, h in zip(whdfs.res, hdfs.res)])} (fp tolerance 1e-9)\")\n",
    "print(f\"Path comparison:   {whdfs.get_paths == hdfs.get_paths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Results\n",
    "#### New plot_sorted Parameter\n",
    "\n",
    "The new `plot_sorted` parameter controls whether paths are plotted in original or sorted (weight-ordered) index space:\n",
    "- `plot_sorted=False` (default): Plot in original index space - HDFS and WHDFS look the same\n",
    "- `plot_sorted=True`: Plot in sorted index space - shows weight-ordered structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results (plot_sorted = False)\n",
    "axis = plot_results.plot(results=whdfs, size=10, plot_sorted=False, axis_labels=True, highlight_top_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sorted results (plot_sorted = True)\n",
    "axis = plot_results.plot(results=whdfs, size=10, plot_sorted=True, axis_labels=True, highlight_top_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing HDFS and WHDFS Results\n",
    "\n",
    "With `auto_sort=True` (default), WHDFS automatically returns paths in **original index space** via `get_paths`, making comparison with HDFS straightforward.\n",
    "\n",
    "**Important**: The internal storage (`res` attribute) differs between HDFS and WHDFS:\n",
    "- `hdfs.res` contains paths in original index space\n",
    "- `whdfs.res` contains paths in sorted index space (for performance)\n",
    "\n",
    "Always use `get_paths` and `get_weights` properties result for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results match (using ==):\", whdfs == hdfs)\n",
    "print(\"Paths match (using get_paths):\", whdfs.get_paths == hdfs.get_paths)\n",
    "print(\"Weights match (using get_weights, within floating-point tolerance):\",\n",
    "      all(np.isclose(whdfs.get_weights, hdfs.get_weights)))\n",
    "print()\n",
    "print(\"Note: whdfs.res != hdfs.res because res contains internal storage\")\n",
    "print(\"  (sorted indices for WHDFS, original indices for HDFS)\")\n",
    "print(\"  Always use get_paths/get_weights or == comparison instead!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
