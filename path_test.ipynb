{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very basic jupyter tutorial for the Hereditary Depth First Search (HDFS) from the pathfinder module.\n",
    "\n",
    "The aim of this exercise is to identify the optimum subset of elements where elements could refer to a sets of features for ML training, Linear Regression or experimental observables. Given access to a pair wise relation matrix - e.g. Pearson Correlation, Fisher Information, Joint Mutual Information, ... - one can construct a Binary Acceptance Matrix (BAM) by defining a threshold (T) below which combination is allowed. The HDFS algorithm will efficiently identify all subsets of elements whose pairwise relations fall below T for all elements in the subset. Thus the HDFS algorithm provides a list of subsets containing minimally 'related' elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "from math import isclose\n",
    "import numpy as np\n",
    "import pathfinder as pf\n",
    "from pathfinder import plot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for the pseudo data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed) \n",
    "print(f\"seed = {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create the \"Binary Acceptance Matrix\" (BAM). \\\n",
    "\\\n",
    "The BAM ($\\rho$) is a symmetric Boolean matrix that provides the pair-wise combination condition i.e element $i$ can be combined with elemet $j$ if $\\rho_{ij}$ = True  \\\n",
    "\\\n",
    "For this example we will create a 'psudo' BAM by randomly generating matrix elements with Boolean values distributed as follows:\n",
    "\n",
    "$ P(\\rho_{ij}=True) = p$ \\\n",
    "\\\n",
    " $P(\\rho_{ij}=False) = 1-p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25                                                                          # Matrix size\n",
    "p = 0.5                                                                         # Distribution of True values \n",
    "pseudo = np.triu(np.random.choice([True, False], size=(N,N), p=[p, 1-p]), 1)    # Construct BAM values \n",
    "pseudo += pseudo.T                                                              # Construct symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exsersise is to identify the optimum subset of elements.\n",
    "The HDFS algorithm identifies **all** allowed subsets elements using the Binary Acceptance Matrix.\n",
    "To help choose the optimum set one can provide a list of weights which will give preference to the highest total path weight sum. \n",
    "If run without weight the \"**find_paths**\" method will return the longest paths as if uniformly weighted to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights= np.sort(np.random.rand(N))[::-1]                                       # Generate pseudo weights (descending order)\n",
    "weights = np.random.rand(N)\n",
    "bam = pf.BinaryAcceptance(pseudo, weights=weights)\n",
    "index_map = bam.sort_bam_by_weight()                           # Provide pseudo BAM and Weights to BinaryAcceptance class\n",
    "plot_results.plot(bam, size=10)                                                          # Plot the BAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the **BinaryAcceptance** Object to **HDFS** and run **find_paths** to get the top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = pf.HDFS(bam, top=5, ignore_subset=True)\n",
    "hdfs.find_paths(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the **BinaryAcceptance** Object to **WHDFS** and run **find_paths** to get the top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whdfs = pf.WHDFS(bam, top=5, ignore_subset=True)\n",
    "whdfs.find_paths(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Path = [2, 4, 5, 7, 11, 14],  Weight = 4.499650470394825,  \n",
    "\n",
    "2: Path = [2, 4, 6, 7, 11],  Weight = 3.992302162921413,  \n",
    "\n",
    "3: Path = [0, 5, 8, 9, 12],  Weight = 3.8649178973867615,  \n",
    "\n",
    "4: Path = [0, 5, 8, 9, 14],  Weight = 3.707504655554509,  \n",
    "\n",
    "5: Path = [0, 8, 9, 12, 13],  Weight = 3.5387637906697584  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHDFS == HDFS\")\n",
    "print(f\"Object comparison: {whdfs.res == hdfs.res}\")\n",
    "print(f\"Weight comparison: {all([isclose(w.weight, h.weight) for w, h in zip(whdfs.res, hdfs.res)])} (fp tolerance 1e-9)\")\n",
    "print(f\"Path comparison:   {all([w.path == h.path for w, h in zip(whdfs.res, hdfs.res)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = plot_results.plot(bam, whdfs, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we provided the weights and binary acceptance in an unsorted format. When '''bam.sort_bam_by_weight()''' is called the method returns an index map to the original unsorted order which can be used to recover the original index reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whdfs.remap_path(index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whdfs.remap_path(index_map) ==  hdfs.remap_path(index_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
